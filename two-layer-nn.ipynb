{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train : (1257, 64)\n",
      "y_Train : (1257,)\n",
      "\n",
      "X_Test : (540, 64)\n",
      "y_Test : (540,)\n"
     ]
    }
   ],
   "source": [
    "X_full = digits.data\n",
    "y_full = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.3)\n",
    "\n",
    "print(\"X_Train :\", X_train.shape)\n",
    "print(\"y_Train :\", y_train.shape)\n",
    "print(\"\\nX_Test :\", X_test.shape)\n",
    "print(\"y_Test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train - np.mean(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model\n",
    "- image normalization \n",
    "- xavier weight initilization\n",
    "- batch normalization\n",
    "- adam optimizer\n",
    "- model ensambles give 2% more accuracy\n",
    "- Inverted drop out (Regularization) + 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return 1. * (x > 0)\n",
    "\n",
    "\n",
    "def cross_entropy(X,y):\n",
    "    m = y.shape[0]\n",
    "    p = stable_softmax(X)\n",
    "\n",
    "    log_likelihood = -np.log(p[range(m),y] + 0.00001)\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n",
    "\n",
    "\n",
    "def delta_cross_entropy(X,y):\n",
    "    m = y.shape[0]\n",
    "    grad = softmax(X)\n",
    "    grad[range(m),y] -= 1\n",
    "    grad = grad/m\n",
    "    return grad\n",
    "\n",
    "\n",
    "def cross_entropy_Loss(z, y):\n",
    "    predict_1 = y * np.log(z)\n",
    "    predict_0 = (1 - y) * np.log(1 - z)\n",
    "    \n",
    "    #print(\"\\n pred1 \\n\", predict_1)\n",
    "    #print(\"\\n pred0 \\n\", predict_0)\n",
    "    \n",
    "    return -sum(predict_1 + predict_0) / X.shape[0]\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "def stable_softmax(X):\n",
    "    exps = np.exp(X - np.max(X))\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "def softmax_grad(softmax):\n",
    "    # Reshape the 1-d softmax to 2-d so that np.dot will do the matrix multiplication\n",
    "    s = softmax.reshape(-1,1)\n",
    "    #print(s.shape)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "\n",
    "def softmax2(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis] # dito\n",
    "    return e_x / div\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(2, 10) * np.sqrt(1. / 64.0 + 10.0)\n",
    "a_sm = softmax2(a)\n",
    "\n",
    "a_sm_grad = softmax_grad(a_sm)\n",
    "a_sm_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.c_[np.ones((X.shape[0],1)), X[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y, lr=0.00005):\n",
    "        self.input      = x\n",
    "        self.w1         = np.random.randn(64, 32) * np.sqrt(1. / 64.0 + 32.0)     #xavier distribution\n",
    "        self.w2         = np.random.randn(32, 10) * np.sqrt(1. / 32.0 + 10.0)\n",
    "        self.y          = y\n",
    "        self.output     = np.zeros(self.y.shape)\n",
    "        self.lr = lr\n",
    "\n",
    "    def feedforward(self):\n",
    "        self.layer1 = relu(self.input@self.w1)\n",
    "        self.output = self.layer1@self.w2\n",
    "        \n",
    "    def backprop(self):\n",
    "        self.w2 = self.w2 - self.lr * self.layer1.T @ delta_cross_entropy(self.output, self.y)\n",
    "        dir_w1 = ((delta_cross_entropy(self.output, self.y) @ self.w2.T).T @ relu_derivative(self.input@self.w1) @ (self.input@self.w1).T @ self.input).T\n",
    "        self.w1 = self.w1 - self.lr * dir_w1\n",
    "\n",
    "    def fit(self, num_epochs=300):\n",
    "        \n",
    "        cost_val = []\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            j =  MSE_loss(self.output, y)\n",
    "            cost_val.append(j)\n",
    "            \n",
    "            self.feedforward_relu()\n",
    "            self.backprop_relu()\n",
    "        return cost_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (1257, 64)\n",
      "w1 (64, 32)\n",
      "w2 (32, 10)\n",
      "y (1257,)\n",
      "y_pred (1257,)\n",
      "w1 after backprop: (64, 32)\n",
      "w2 after backprop: (32, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-748a4aefe270>:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return e_x / e_x.sum(axis=0) # only difference\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(X_train, y_train, 0.00005)\n",
    "\n",
    "print(\"X\", nn.input.shape)\n",
    "print(\"w1\", nn.w1.shape)\n",
    "print(\"w2\", nn.w2.shape)\n",
    "print(\"y\", nn.y.shape)\n",
    "print(\"y_pred\", nn.output.shape )\n",
    "\n",
    "layer1 = relu(nn.input@nn.w1)\n",
    "layer2 = (layer1@nn.w2)\n",
    "#print(layer2[0:2])\n",
    "layer2 = layer1@nn.w2\n",
    "\n",
    "nn.feedforward()\n",
    "y_pred = nn.output\n",
    "#print(\"\\n\", nn.output[0:2])\n",
    "\n",
    "cross_entropy(y_pred, y_train)\n",
    "\n",
    "delta_cross_entropy(y_pred, y_train).shape\n",
    "\n",
    "nn.backprop()\n",
    "\n",
    "print(\"w1 after backprop:\", nn.w1.shape)\n",
    "print(\"w2 after backprop:\", nn.w2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-b631e27b23a9>:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return e_x / e_x.sum(axis=0) # only difference\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat =  ((delta_cross_entropy(nn.output, nn.y) @ nn.w2.T).T @ relu_derivative(nn.input@nn.w1) @ (nn.input@nn.w1).T @ X).T\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257, 32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_derivative(nn.input@nn.w1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change y into numpy array\n",
    "uq = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "y = np.zeros((X.shape[0], 10))\n",
    "\n",
    "for i in range(0, 10):\n",
    "    for j in range(0, len(y_train)):\n",
    "        if y_train[j] == uq[i]:\n",
    "            y[j, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "\n",
    "w = np.random.normal(0, 0.01, (64, 32))\n",
    "\n",
    "nn = NeuralNetwork(X, y, 0.00005)\n",
    "\n",
    "print(\"X: \", nn.input.shape)\n",
    "print(\"w1\", nn.weights1.shape)\n",
    "print(\"w2\", nn.weights2.shape)\n",
    "print(\"y\", nn.y.shape)\n",
    "print(\"y_pred\", nn.output.shape)\n",
    "\n",
    "#nn.feedforward_sigmoid()\n",
    "#nn.backprop_sigmoid()\n",
    "#nn.fit(10000)\n",
    "epochs = 20\n",
    "cost_val = nn.fit(epochs )\n",
    "\n",
    "#print(\"y_pred\", nn.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, epochs), cost_val, color ='blue')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"cost (J)\")\n",
    "plt.title(\"Convergence of gradient descent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_pred\", nn.output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(64, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    cnt = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        temp = 0\n",
    "        ind = -1\n",
    "        for j in range(10):\n",
    "            if y_pred[i][j] > temp:\n",
    "                temp = y_pred[i][j]\n",
    "                ind = j\n",
    "        if y[i][ind] == 1:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    print(\"accuracy: \", cnt/y_pred.shape[0])\n",
    "\n",
    "\n",
    "accuracy(nn.output, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
